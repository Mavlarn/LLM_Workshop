{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1409b5-035c-4e66-8ed1-7e06865ad52f",
   "metadata": {},
   "source": [
    "## 使用SageMaker的BYOS(Bring Your Oen Script)方式部署大语言模型\n",
    "\n",
    "利用SageMaker部署大语言模型的原理如下：\n",
    "\n",
    "<img src=\"imgs/sagemaker_deploy_model.jpg\" style=\"width: 850px;\"></img>\n",
    "\n",
    "SageMaker提供了几种不同的Container来部署模型，[DJL](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-tutorials-deepspeed-djl.html)是AWS提供的用于部署大模型的容器。使用它，我们可以使用DeepSpeed、HuggingFace、FatserTransformer来进行加速。\n",
    "\n",
    "<img src=\"imgs/djl.jpg\" style=\"width: 850px;\"></img>\n",
    "\n",
    "目前不同的加速框架支持的模型如下（2023年3月）：\n",
    "\n",
    "<img src=\"imgs/djl_models.jpg\" style=\"width: 850px;\"></img>\n",
    "\n",
    "目前DeepSpeed已经支持LLaMA，并且性能提升达到3倍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da04a2-c943-4680-864c-678546f920c7",
   "metadata": {},
   "source": [
    "### 可部署的模型\n",
    "\n",
    "使用DJL容器部署模型，对于一部分支持的模型，只需要通过定义DeepSpeedModel 或 HuggingFaceAccelerateModel 来部署即可，但是对于一些模型，可能需要设置 *trust_custom_code=True* ，或者需要自己的推理脚本，这时候，就使用自己的脚本，打包后传到S3，使用 DJL 的推理容器来进行部署。\n",
    "\n",
    "这里，提供的部署脚本有：\n",
    "1. chatglm2\n",
    "2. cn-alpaca\n",
    "3. baichuan2\n",
    "\n",
    "如果需要其他的模型，可以使用类似的方式提供脚本。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e32ef-de3e-4d0e-b1f5-cbe81b1c1ad2",
   "metadata": {},
   "source": [
    "### 下载模型到S3\n",
    "\n",
    "如果是国内部署，从huggingface上下载模型可能会很慢，甚至经常因为超时而出错，所以可以先下载到本地后，上传到S3，然后从s3地址部署。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac1295-b374-417f-9970-c1c8dbd1bd21",
   "metadata": {
    "tags": []
   },
   "source": [
    "这里使用 *Baichuan2-13B-Chat-4bits* 模型，它是13B的模型，正常部署需要至少32GB显存，24GB显存的机器能部署，然后一推理就会OOM。但是这里使用4bit的量化版本，只需要16GB显存的机型，就能部署使用，而且模型的能力下降也不多，从官方提供的benchmark来看，只有微小的下降。\n",
    "\n",
    "先将模型下载到本地。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31f3e714-948f-42a8-a8de-1f3c5acd5522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 需要先安装依赖\n",
    "# %pip install huggingface_hub --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0eed7-863c-433e-bba6-cc5e44c7980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# - This will download the model into the ./model directory where ever the jupyter file is running\n",
    "local_model_path = Path(\"/home/ec2-user/SageMaker/models/baichuan-inc--Baichuan2-13B-Chat-4bits\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "model_name = \"baichuan-inc/Baichuan2-13B-Chat-4bits\"\n",
    "# Only download pytorch checkpoint files\n",
    "allow_patterns = [\"*.json\", \"*.bin\", \"*.txt\", \"*.model\", \"*.py\"]\n",
    "\n",
    "# - Leverage the snapshot library to donload the model since the model is stored in repository using LFS\n",
    "model_download_path = snapshot_download(\n",
    "    repo_id=model_name,\n",
    "    cache_dir=Path(\"/home/ec2-user/SageMaker/models\"),\n",
    "    local_dir_use_symlinks=False,\n",
    "    local_dir=local_model_path,\n",
    "    allow_patterns=allow_patterns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645cb017-5158-4b1d-a7d4-5c3c5897c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to s3\n",
    "key_prefix=\"mt_models_uploaded/baichuan-inc--Baichuan2-13B-Chat-4bits\"\n",
    "\n",
    "model_artifact = sess.upload_data(path=model_download_path, key_prefix=key_prefix)\n",
    "print(f\"Model uploaded to --- > {model_artifact}\")\n",
    "print(f\"You can set option.s3url={model_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209153ec-d0cb-4fa1-aaf7-ccf7c6a948b0",
   "metadata": {},
   "source": [
    "将上传的地址，如“s3://sagemaker-us-east-1-568765279027/mt_models_uploaded/baichuan-inc--Baichuan2-13B-Chat-4bits” 提换到 djl-baichuan2-13b-4bits 目录中的 option.s3url 路径\n",
    "```\n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "option.enable_streaming=True\n",
    "option.predict_timeout=240\n",
    "option.s3url = s3://sagemaker-us-east-1-568765279027/mt_models_uploaded/baichuan-inc--Baichuan2-13B-Chat-4bits/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2586d-30c9-45f0-b232-a1f8c3b9bd0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 部署"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe93c1-29b8-40e3-9c82-7f7ce1b2ffaf",
   "metadata": {},
   "source": [
    "准备：\n",
    "1. 升级boto3, sagemaker python sdk  \n",
    "2. 准备inference.py, requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18eb1530-76ea-4bc1-b5e3-7219de5f8ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 如果需要，更新sagemaker和 aws python sdk boto3\n",
    "# %pip install --upgrade awscli boto3\n",
    "# %pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d887da0-7abe-4056-b33e-d6d584219269",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "2.196.0\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d80dad-12b2-4228-97db-69a89fcf951a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker-us-east-1-568765279027\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session._region_name # region name of the current environment\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7e43b-5e84-4a4a-85e6-599e9e47c5a9",
   "metadata": {},
   "source": [
    "接下来，我们使用Sagemaker进行模型部署。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e3b6e6-58d2-4053-852d-e5d76e9afbab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 我们部署 chatglm2 \n",
    "# model_code = \"chatglm2\"\n",
    "# model_code = \"cn-alpaca2-7b\"\n",
    "model_code = \"baichuan2\"\n",
    "model_dir = \"baichuan2-13b-4bits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ede4043-1ef2-4d94-be21-7b2228c21963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'djl-baichuan2-13b-4bits'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# engine = \"hf\"  # using huggingface\n",
    "engine = \"py\"  # using Python\n",
    "engine = \"ds\"  # using deepspeed\n",
    "# engine = \"ft\"  # using fastertransformer\n",
    "\n",
    "dir_name = \"djl-\" + engine + \"-\" + model_code\n",
    "dir_name = \"djl-\" + model_dir\n",
    "dir_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb46205f-f527-4805-8156-ed8a65ea3366",
   "metadata": {},
   "source": [
    "选择要使用的镜像，最新版是\"0.23.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0cb124-248c-47b6-95f5-43b86455a765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f69ccaef-64e2-4b2b-9203-bb65459d6b41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.24.0-deepspeed0.10.0-cu118\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "inference_image_uri = image_uris.retrieve(\n",
    "    framework=\"djl-deepspeed\",\n",
    "    region=region,\n",
    "    version=\"0.24.0\"\n",
    ")\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7fc96d2-4aef-48d1-ad1e-5353977f106e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 0: cd: LLM_bc2_4bit_stream_deploy_code: No such file or directory\n",
      "djl-baichuan2-13b-4bits/\n",
      "djl-baichuan2-13b-4bits/.ipynb_checkpoints/\n",
      "djl-baichuan2-13b-4bits/.ipynb_checkpoints/serving-checkpoint.properties\n",
      "djl-baichuan2-13b-4bits/.ipynb_checkpoints/model-checkpoint.py\n",
      "djl-baichuan2-13b-4bits/.ipynb_checkpoints/requirements-checkpoint.txt\n",
      "djl-baichuan2-13b-4bits/serving.properties\n",
      "djl-baichuan2-13b-4bits/requirements.txt\n",
      "djl-baichuan2-13b-4bits/model.py\n"
     ]
    }
   ],
   "source": [
    "# 需要将文件夹打包传到S3上，部署的时候需要\n",
    "\n",
    "!rm {dir_name}.tar.gz\n",
    "!cd LLM_bc2_4bit_stream_deploy_code && rm -rf \".ipynb_checkpoints\"\n",
    "!tar czvf {dir_name}.tar.gz {dir_name}/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7fc1f3-54b3-426f-a569-f5ca08a9b8b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deploy_code/djl-baichuan2-13b-4bits'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_code_prefix = (\n",
    "    \"deploy_code/\" + dir_name  # folder within bucket where code artifact will go\n",
    ")\n",
    "s3_code_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543262ea-dcb3-4a75-99ca-b3448cdbcf69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "djl_s3_code_artifact = sagemaker_session.upload_data(dir_name + \".tar.gz\", bucket, s3_code_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b078cdaf-9c00-44cb-9116-3e00e5e20a24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mt-djl-baichuan2-13b-4bits-g5'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name = 'mt-'+dir_name+'-g5'\n",
    "endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988afe9e-6eae-4d36-846a-a1767cfa6cc7",
   "metadata": {},
   "source": [
    "然后部署该模型为 Sagemaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05336baa-0139-4bf9-afb2-5e42152de19c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "\n",
    "model = Model(\n",
    "    name=endpoint_name + \"-model\",\n",
    "    image_uri=inference_image_uri, \n",
    "    model_data=djl_s3_code_artifact, \n",
    "    role=role\n",
    ")\n",
    "\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    container_startup_health_check_timeout=600\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccbb346a-995c-48ce-8409-d68a42c0eca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mt-djl-baichuan2-13b-4bits-g5'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8464819-ad0c-45ab-9f94-bd7548257287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import serializers, deserializers\n",
    "\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    serializer=serializers.JSONSerializer(), \n",
    "    deserializer=deserializers.JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea8ad33-195d-47e7-b7e3-c9eaa92c0fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'prompt_generator' from '/home/ec2-user/SageMaker/LLM_Workshop/prompt_generator.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from prompt_generator import generate_prompt as gen_prompt\n",
    "import prompt_generator as pg\n",
    "import importlib\n",
    "\n",
    "importlib.reload(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ad5ae9-8909-4319-84dd-86df32380019",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': [{'role': 'system', 'content': '信息抽取'},\n",
       "  {'role': 'user', 'content': '2022年世界杯的冠军是阿根廷队伍，梅西是MVP\\n问题：国家名，人名\\n答案：'}],\n",
       " 'parameters': {'do_sample': False,\n",
       "  'temperature': 0.3,\n",
       "  'top_k': 50,\n",
       "  'max_new_tokens': 2048}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload = pg.create_payload(\"2022年世界杯的冠军是阿根廷队伍，梅西是MVP\\n问题：国家名，人名\\n答案：\", instruct='信息抽取', model_code=model_code)\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67a2b7eb-05a4-4b37-8fbf-e4fedf50cabc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.5 ms, sys: 843 µs, total: 25.3 ms\n",
      "Wall time: 4.21 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'outputs': '国家名：阿根廷\\n人名：C罗（克里斯蒂亚诺·罗纳尔多）'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# payload = pg.create_payload(\"信息抽取：\\n2022年世界杯的冠军是阿根廷队伍，梅西是MVP\\n问题：国家名，人名\\n答案：\", model_code)\n",
    "payload = pg.create_payload(\"2022年世界杯的冠军是阿根廷队伍，C罗是MVP\\n问题：国家名，人名\\n答案：\", instruct='信息抽取', model_code=model_code)\n",
    "predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2288b39-62cb-4fb8-aa38-78036f5c1d2a",
   "metadata": {},
   "source": [
    "如果部署过程中出现错误，部署失败，通过下面的方式删除endpoint以及相应的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b3fc9934-4e30-4ab3-962f-e08e4739a876",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mt-djl-baichuan2-13b-4bits-g4dn'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37ba118c-12bd-426a-bc59-aec13ac28f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import serializers, deserializers\n",
    "\n",
    "del_predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "# del_predictor.delete_model()\n",
    "# del_predictor.delete_endpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee63cd2f-8f70-478e-bf13-20b8e32758bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "问题:  [{'role': 'user', 'content': '写一首关于交通信号灯的诗'}] \n",
      "回答:\n",
      " 在这繁华的城市里，\n",
      "交通信号灯如舞者般翩翩起舞。\n",
      "红、黄、绿三色交织，\n",
      "为这喧嚣的世界描绘出一幅画卷。\n",
      "\n",
      "红灯亮起，如同烈焰燃烧，\n",
      "警示着行人们暂停脚步。\n",
      "黄灯闪烁，犹如黎明前的曙光，\n",
      "提醒着我们即将进入新的时光。\n",
      "\n",
      "绿灯闪耀，希望之光洒满大地，\n",
      "我们欢快地穿越马路，奔向远方。\n",
      "在这瞬息万变的世界里，\n",
      "交通信号灯是我们生活的指引。\n",
      "\n",
      "它们无声地守护着每一个路口，\n",
      "为我们划分出安全的道路。\n",
      "无论白天还是黑夜，\n",
      "它们始终屹立在那里，不离不弃。\n",
      "\n",
      "当我们感叹城市的繁华与喧嚣，\n",
      "不要忘了这些默默付出的信号灯。\n",
      "它们用红、黄、绿三种色彩，\n",
      "为我们描绘出一个和谐的交通世界。\n",
      "\n",
      "让我们向这些无声的守护者致敬，\n",
      "感谢它们为我们的生活带来安宁。\n",
      "在这繁华的都市中，\n",
      "交通信号灯是我们的守护天使。\n",
      "\n",
      "\n",
      "问题:  [{'role': 'user', 'content': '陨石为什么总能落在陨石坑里?'}] \n",
      "回答:\n",
      " 实际上，并不是所有的陨石都会落在陨石坑中。然而，大多数情况下，当陨石撞击地球表面时，它会形成一个坑洞，这个坑洞通常被称为陨石坑。这是因为陨石的重量和速度使其对地表产生了足够的破坏力，从而改变了周围的物质并形成了这个坑洞。\n",
      "\n",
      "在某些情况下，陨石可能会在陆地或水面上降落，而不是在固体表面上。在这种情况下，陨石可能会与地表的物质混合在一起，或者被水流带走。因此，在这些情况下，我们可能不会看到明显的陨石坑。\n",
      "\n",
      "总的来说，虽然并非所有陨石都会落在陨石坑中，但大多数陨石在撞击地表时会形成陨石坑。\n",
      "\n",
      "\n",
      "问题:  [{'role': 'user', 'content': '为什么爸妈结婚没叫我参加婚礼?'}] \n",
      "回答:\n",
      " 因为你在当时还没有出生。当你出生时，你的父母已经结婚了。\n"
     ]
    }
   ],
   "source": [
    "inputs= [\n",
    "    pg.create_payload(\"写一首关于交通信号灯的诗\", model_code=model_code),\n",
    "    pg.create_payload(\"陨石为什么总能落在陨石坑里?\", model_code=model_code),\n",
    "    pg.create_payload(\"为什么爸妈结婚没叫我参加婚礼?\", model_code=model_code)\n",
    "]\n",
    "response = predictor.predict(inputs[0])\n",
    "print(\"\\n\\n问题: \", inputs[0][\"inputs\"], \"\\n回答:\\n\", response[\"outputs\"])\n",
    "response = predictor.predict(inputs[1])\n",
    "print(\"\\n\\n问题: \", inputs[1][\"inputs\"], \"\\n回答:\\n\", response[\"outputs\"])\n",
    "response = predictor.predict(inputs[2])\n",
    "print(\"\\n\\n问题: \", inputs[2][\"inputs\"], \"\\n回答:\\n\", response[\"outputs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e667be-8e56-40bf-9129-05f93ccb4b27",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 通过Sagemaker Endpoint调用\n",
    "我们已经将模型部署到了Sagemaker Endpoint上，我们就可以通过这个Endpoint名称，来调用模型进行推理，这样即使你停止了这个notebook，也能使用已经部署的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6726e86-e665-4d31-82f8-6ca08decdb65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('runtime.sagemaker')\n",
    "# sagemaker_endpoint_name = \"mt-chatglm2-6b-ft-g4dn\"\n",
    "sagemaker_endpoint_name = \"mt-djl-baichuan2-13b-4bits-g4dn\"\n",
    "\n",
    "def query_endpoint(encoded_json):\n",
    "    response = client.invoke_endpoint(EndpointName=sagemaker_endpoint_name, ContentType='application/json', Body=encoded_json)\n",
    "    model_predictions = json.loads(response['Body'].read())\n",
    "    generated_text = model_predictions[\"outputs\"]\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8dc5f45a-0d61-458f-a29f-06e9f35d6bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baichuan2'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bcdf467-c041-4468-9368-94a509dc72e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国家名：阿根廷\n",
      "人名：梅西\n",
      "CPU times: user 24.7 ms, sys: 0 ns, total: 24.7 ms\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "payload = pg.create_payload(\"2022年世界杯的冠军是阿根廷队伍，梅西是MVP\\n问题：国家名，人名\\n答案：\", instruct='信息抽取', model_code=model_code)\n",
    "resp_test = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(resp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f507036-13e2-4cf5-a251-49076b8e6650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "蓝天白云真美丽，白云蓝天真清新。\n",
      "16\n",
      "CPU times: user 3.76 ms, sys: 0 ns, total: 3.76 ms\n",
      "Wall time: 686 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\"inputs\": \"写一首有关蓝天白云的四言诗。\"}\n",
    "\n",
    "answer = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(answer)\n",
    "print(len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ec18913-b092-4b75-b5a0-ad11f4b689ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "水光针一般建议一个月左右打一次。\n",
      "CPU times: user 27.5 ms, sys: 821 µs, total: 28.4 ms\n",
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "propmt = \"\"\"使用下面的已知内容，简洁、直接的回答最后的问题。不要使用已有的知识，不要编造答案，答案越简洁越好。如果你从上下文中无法知道答案，就直接返回'根据已知信息无法回答该问题.'。\n",
    "\n",
    "已知内容:\n",
    "Q:水光针多久打一次呢?效果能维持多久?\n",
    "A:水光针一般建议一个月左右打一次,大概就是28天,因为刚好皮肤的周期是这么久。\n",
    "如果是第一次打水光，吸收比较快，也一些专家建议第一次和第二次间隔半个月,二十天左右就可以打第二次,之后在打就间隔一个月左右。\n",
    "水光的功效主要看你加了什么成分，正常来说的话，一般的营养成分大概是一到两个月。可以维持,如果里面加了肉毒素的话，效果可以维持3个月\n",
    "左右,所以像水光如果你不加肉毒素，是每个月都可以操作注射的，越打皮肤会越好。\n",
    "\n",
    "Q:水光针做完一次可以维持多久?\n",
    "A:对于肤质干燥且疏于保养的人而言，其效果大约能维持3个月左右，保养越好，效果维持时间相应越长。具体来说，水光针注射效果与接受注射的次数有关，连续进行三次注射后，效果可以维持1—2年左右，但根据个人体质、肤质、生活习惯等不同，具体的维持时间也会有所差异。\n",
    "\n",
    "Q：水光针怎样打效果更好?\n",
    "A:水光针的话，我认为用机器打，特别是这个34G的16针头去操作的话，效果一定会更好，然后再用到好的产品，那么就事半功倍了，然后术后的话可以多敷修复的面膜。然后在就是持续的去打，那么可以，达到一个一加一大于二的效果。\n",
    "\n",
    "Q：水光针多久打一次呢?效果能维持多久?\n",
    "A：水光针一般建议一个月左右打一次,大概就是28天,因为刚好皮肤的周期是这么久。\n",
    "如果是第一次打水光，吸收比较快，也一些专家建议第一次和第二次间隔半个月,二十天左右就可以打第二次,之后在打就间隔一个月左右。\n",
    "水光的功效主要看你加了什么成分，正常来说的话，一般的营养成分大概是一到两个月。可以维持,如果里面加了肉毒素的话，效果可以维持3个月\n",
    "左右,所以像水光如果你不加肉毒素，是每个月都可以操作注射的，越打皮肤会越好。\n",
    "\n",
    "Q:脸部、肚子溶脂针多久见效?\n",
    "A:一般打完溶脂针的话就是五到七天会有效果，但是效果的显著程度因人而异，有的人打一次溶脂针效果就比较明显，但是有的人需要多次注射才会有明显的效果。除此之外，打完溶脂针以后，自身对手术部位的护理也会影响到溶脂针的见效速度与效果的好坏。\n",
    "在打完溶脂针以后，要尽量的保持注射部位的清洁,在一天之内不能沾水，恢复期间也要避免外界的污染，更不能化妆，不要在这个注射部位涂抹外用的一些药物,以免刺激到注射的部位，影响溶脂针的一个效果，见效的时间也会因此而延长。\n",
    "想要溶脂针的效果更好的,见效更快的话，多喝水也是可以起到一些的作用，虽然说打完溶脂针以后不能沾水，但是我们可以多喝水，最好是每天饮用一升以上的水，不仅可以促进身体的新陈代谢，水循环，对注射部位的恢复也会起到辅助的作用。\n",
    "溶脂针就是注射一次,就有一次的效果,一般的话是按照疗程来注射，效果是最好的,疗程一般是六到八周左右，每两到三周就可以进行二次注射。\n",
    "正常是第一次注射就能看到效果，第二次注射的时候的效果更加明显，第三次注射的时候就起到了一个巩固的作用。\n",
    "\"\"\"\n",
    "payload = pg.create_payload(\"水光针多久打一次?\", instruct=propmt, model_code=model_code)\n",
    "\n",
    "# {\"inputs\": propmt, \"parameters\": {'temperature': 0.01}}\n",
    "resp_test = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(resp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdab8b72-07f0-4736-ab5f-abb6668eaff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5a61c459-c66a-4838-8e98-a853a3c15056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4加2等于6。\n",
      "CPU times: user 4.27 ms, sys: 0 ns, total: 4.27 ms\n",
      "Wall time: 464 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\"inputs\": \"4加2等于几？\"}\n",
    "resp_test = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(resp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad9bc6d0-38d9-4217-a510-b13155297fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3加8等于11，再乘以3还是11。\n",
      "CPU times: user 3.96 ms, sys: 0 ns, total: 3.96 ms\n",
      "Wall time: 962 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ChatGLM支持通过history传递聊天历史\n",
    "payload = {\n",
    "    \"inputs\": \"再乘以3呢？\",\n",
    "    \"history\": [(\"数学计算：\\n3加8等于几？\\n答案：\", \"3加8等于11。\")]}\n",
    "resp_test = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(resp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25802a57-844a-43cc-a837-a5ab2916052f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e657e006-faf6-4d41-82d8-629454fd2267",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 删除 EndPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8fc003-948f-43aa-af00-ddf25902852c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import serializers, deserializers\n",
    "\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name='mt-djl-baichuan2-13b-4bits-g4dn', \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    serializer=serializers.JSONSerializer(), \n",
    "    deserializer=deserializers.JSONDeserializer()\n",
    ")\n",
    "\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81af0f-edba-47fe-91f0-354196a23644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom (mt_python3)",
   "language": "python",
   "name": "mt_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
