{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1409b5-035c-4e66-8ed1-7e06865ad52f",
   "metadata": {},
   "source": [
    "## 使用SageMaker JumpStart 方式部署大语言模型\n",
    "\n",
    "利用SageMaker部署大语言模型的原理如下：\n",
    "\n",
    "<img src=\"imgs/sagemaker_deploy_model.jpg\" style=\"width: 850px;\"></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da04a2-c943-4680-864c-678546f920c7",
   "metadata": {},
   "source": [
    "### 可部署的模型\n",
    "\n",
    "这里提供了多个模型，以及相应的script用于部署，提供的模型有：\n",
    " * LLaMA\n",
    " * LLaMA2系列\n",
    " * falcon系列\n",
    "\n",
    "所需的脚本在相应的`djl-*`文件夹里。\n",
    "\n",
    "模型不同，可使用的加速框架不同，如huggingface、deepspeed等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2586d-30c9-45f0-b232-a1f8c3b9bd0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 部署"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe93c1-29b8-40e3-9c82-7f7ce1b2ffaf",
   "metadata": {},
   "source": [
    "准备：\n",
    "1. 升级boto3, sagemaker python sdk  \n",
    "2. 准备inference.py, requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb1530-76ea-4bc1-b5e3-7219de5f8ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 如果需要，更新sagemaker和 aws python sdk boto3\n",
    "# !pip install --upgrade boto3\n",
    "# !pip install --upgrade sagemaker\n",
    "# !pip install ipywidgets==7.0.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d80dad-12b2-4228-97db-69a89fcf951a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-568765279027\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session._region_name # region name of the current environment\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7e43b-5e84-4a4a-85e6-599e9e47c5a9",
   "metadata": {},
   "source": [
    "接下来，我们使用Sagemaker进行模型部署。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558c8827-c9e6-4590-bd92-aa783f08b5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id, model_version, = (\n",
    "    \"huggingface-llm-falcon-7b-instruct-bf16\",\n",
    "    \"*\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f17487d9-24ae-4fc0-a759-01463b6c8918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "# ??JumpStartModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2d7cb5a-820d-4096-8947-6d6bd8635059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "my_model = JumpStartModel(\n",
    "    model_id = model_id,\n",
    "    name='mt-jump-falcon-7b-instruct-model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa2c4da5-0310-42fe-b862-3be5f249cb68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.0-tgi0.8.2-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "print(my_model.image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd35bf48-82b8-481c-9f2a-843873d23327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://jumpstart-cache-prod-us-east-1/huggingface-infer/prepack/v1.0.0/infer-prepack-huggingface-llm-falcon-7b-instruct-bf16.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# 可以下载模型源码，看看推理的代码。\n",
    "print(my_model.model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1185c-626f-44e9-b182-b37b83034b2e",
   "metadata": {},
   "source": [
    "可以看到，在JumoStart上部署falcon模型，是使用的 *tgi 0.8.2* 的容器部署的。endpoint_name = 'mt-jump-falcon-7b-instruct-g4dn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8f9666f-39cb-4582-91bf-605d6ebb9e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = 'mt-jump-falcon-7b-instruct-g5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cc8b83e-f069-48b3-b24a-b51b536ee382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "predictor = my_model.deploy(\n",
    "    endpoint_name=endpoint_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2288b39-62cb-4fb8-aa38-78036f5c1d2a",
   "metadata": {},
   "source": [
    "如果部署过程中出现错误，部署失败，通过下面的方式删除endpoint以及相应的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37ba118c-12bd-426a-bc59-aec13ac28f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import serializers, deserializers\n",
    "\n",
    "# endpoint_name = 'mt-llama2-7b-g4dn'\n",
    "del_predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    serializer=serializers.JSONSerializer(), \n",
    "    deserializer=deserializers.JSONDeserializer())\n",
    "# del_predictor.delete_model()\n",
    "# del_predictor.delete_endpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb3e4be-1378-495e-9d32-b047279576e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee63cd2f-8f70-478e-bf13-20b8e32758bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs= [\n",
    "    {\"inputs\": \"写一首关于交通信号灯的诗\"},\n",
    "    {\"inputs\": \"陨石为什么总能落在陨石坑里?\"},\n",
    "    {\"inputs\": \"为什么爸妈结婚没叫我参加婚礼?\"}\n",
    "]\n",
    "\n",
    "response = predictor.predict(inputs[2])\n",
    "\n",
    "# print(\"\\n\\n问题: \", inputs[0][\"inputs\"], \"\\n回答:\\n\", response[\"outputs\"])\n",
    "# response = predictor.predict(inputs[1])\n",
    "# print(\"\\n\\n问题: \", inputs[1][\"inputs\"], \"\\n回答:\\n\", response[\"outputs\"])\n",
    "# response = predictor.predict(inputs[2])\n",
    "# print(\"\\n\\n问题: \", inputs[2][\"inputs\"], \"\\n回答:\\n\", response[\"outputs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4947d323-7ee1-4694-8bd7-bad1ac054f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"\\nI'm sorry, I cannot answer that question as I do not have enough context. Can\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e667be-8e56-40bf-9129-05f93ccb4b27",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 通过Sagemaker Endpoint调用\n",
    "我们已经将模型部署到了Sagemaker Endpoint上，我们就可以通过这个Endpoint名称，来调用模型进行推理，这样即使你停止了这个notebook，也能使用已经部署的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6726e86-e665-4d31-82f8-6ca08decdb65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "def query_endpoint(encoded_json):\n",
    "    response = client.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/json', Body=encoded_json)\n",
    "    model_predictions = json.loads(response['Body'].read())\n",
    "    generated_text = model_predictions[\"outputs\"]\n",
    "    return generated_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bcdf467-c041-4468-9368-94a509dc72e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国家名:阿根廷\n",
      "人名:梅西\n",
      "CPU times: user 0 ns, sys: 4.17 ms, total: 4.17 ms\n",
      "Wall time: 556 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "payload = {\"inputs\": \"信息抽取：\\n2022年世界杯的冠军是阿根廷队伍，梅西是MVP\\n问题：国家名，人名\\n答案：\", \"parameters\": {\"temperature\": 0.01}}\n",
    "resp_test = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(resp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f507036-13e2-4cf5-a251-49076b8e6650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天空之所以呈现蓝色,是由于光的散射现象造成的。当太阳光穿过大气层时,光被大气中的分子和小颗粒散射,这些颗粒包括氧气、氮气和水蒸气等分子。这些分子吸收较短波长的光,如紫色和蓝色,而较长波长的光,如红色和橙色,则被分散得更少。\n",
      "\n",
      "由于蓝色光的波长比红色光短,因此它更容易被分散,而在大气层中被散射的程度也更高,因此在天空的观察中,我们看到了大量的蓝色光。这也是为什么在日落或日出时,太阳光穿过更长的大气层路径,较多的光被散射为红色和橙色,天空呈现出橙色或红色的原因。\n",
      "231\n",
      "CPU times: user 3.32 ms, sys: 386 µs, total: 3.71 ms\n",
      "Wall time: 8.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\"inputs\": \"天为什么是蓝色的？\"}\n",
    "answer = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(answer)\n",
    "print(len(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a61c459-c66a-4838-8e98-a853a3c15056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4加2等于6。\n",
      "CPU times: user 3.48 ms, sys: 0 ns, total: 3.48 ms\n",
      "Wall time: 446 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\"inputs\": \"4加2等于几？\"}\n",
    "resp_test = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(resp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad9bc6d0-38d9-4217-a510-b13155297fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果你将11乘以3,那么答案是33。\n",
      "CPU times: user 871 µs, sys: 3.07 ms, total: 3.94 ms\n",
      "Wall time: 874 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ChatGLM支持通过history传递聊天历史\n",
    "payload = {\n",
    "    \"inputs\": \"再乘以3呢？\",\n",
    "    \"history\": [(\"数学计算：\\n3加8等于几？\\n答案：\", \"3加8等于11。\")]}\n",
    "resp_test = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(resp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25802a57-844a-43cc-a837-a5ab2916052f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e657e006-faf6-4d41-82d8-629454fd2267",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 删除 EndPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e8fc003-948f-43aa-af00-ddf25902852c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e82fbb-41b9-4615-a5bf-d2c46ca5a33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef391c-4cd9-4908-b814-97fee6154785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab0ca1-48fd-471b-b216-d4b2da30f50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67263442-ad90-4fcf-90e6-121163133fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "from sagemaker.djl_inference import DeepSpeedModel\n",
    "\n",
    "class MTDeepSpeedModel(DeepSpeedModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_id: str,\n",
    "        role: str,\n",
    "        trust_remote_code: bool = True,\n",
    "        **kwargs,\n",
    "    ):  \n",
    "        super().__init__(\n",
    "            model_id, role, **kwargs,\n",
    "        )\n",
    "        self.trust_remote_code = trust_remote_code\n",
    "        \n",
    "    def generate_serving_properties(self, serving_properties=None) -> Dict[str, str]:\n",
    "        serving_properties = super(MTDeepSpeedModel, self).generate_serving_properties(\n",
    "            serving_properties=serving_properties\n",
    "        )\n",
    "        serving_properties[\"option.trust_remote_code\"] = self.trust_remote_code\n",
    "        return serving_properties\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e73a9ae2-5593-4394-9557-05defa23d1ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MTDeepSpeedModel(\n",
    "    model_id=\"s3://sagemaker-us-east-1-568765279027/mt_models_uploaded/THUDM--chatglm2-6b\",\n",
    "    role=role,\n",
    "    number_of_partitions=1,\n",
    "    trust_remote_code=True,\n",
    "    max_tokens=4096,\n",
    "    dtype=\"fp16\",\n",
    "    task=\"text-generation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf39926-cf5d-4e0c-9e65-5d5185cd58ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'engine': 'DeepSpeed',\n",
       " 'option.entryPoint': 'djl_python.deepspeed',\n",
       " 'option.model_id': 's3://sagemaker-us-east-1-568765279027/mt_models_uploaded/THUDM--chatglm2-6b',\n",
       " 'option.tensor_parallel_degree': 1,\n",
       " 'option.task': 'text-generation',\n",
       " 'option.dtype': 'fp16',\n",
       " 'option.max_tokens': 4096,\n",
       " 'option.triangular_masking': True,\n",
       " 'option.return_tuple': True,\n",
       " 'option.trust_remote_code': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_serving_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d97689-e4cf-4642-be8b-5f7b84f6c05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05336baa-0139-4bf9-afb2-5e42152de19c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------"
     ]
    }
   ],
   "source": [
    "from sagemaker.djl_inference import DeepSpeedModel\n",
    "\n",
    "instance_type = \"ml.g4dn.2xlarge\"\n",
    "endpoint_name = 'mt-'+dir_name+'-g4dn'\n",
    "\n",
    "model = MTDeepSpeedModel(\n",
    "    djl_version=\"0.23.0\",\n",
    "    model_id=\"s3://sagemaker-us-east-1-568765279027/mt_models_uploaded/THUDM--chatglm2-6b\",\n",
    "    role=role,\n",
    "    number_of_partitions=1,\n",
    "    trust_remote_code=True,\n",
    "    max_tokens=4096,\n",
    "    dtype=\"fp16\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    container_startup_health_check_timeout=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2b7eb-05a4-4b37-8fbf-e4fedf50cabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d047123-15b8-4271-b3ef-99afd385b5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaae7a4-7d42-48d2-bf9e-603806840bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e5187-53de-4ed3-9ffa-ec01855bfae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef4fd4b-cb34-4022-811b-d9c9ff7d9cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c0465-e559-4aaa-b501-6ccdfa7d100c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f124bb73-8f39-4d74-8e9f-6d1c6f601519",
   "metadata": {},
   "source": [
    "然后部署该模型为 Sagemaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81af0f-edba-47fe-91f0-354196a23644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom (mt_python3)",
   "language": "python",
   "name": "mt_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
