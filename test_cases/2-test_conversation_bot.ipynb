{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd60e60-ec2b-47d9-af02-d126c91a0ccb",
   "metadata": {},
   "source": [
    "### 测试LLM的多轮对话能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e736e0-8577-4334-ad46-a5570e52896a",
   "metadata": {},
   "source": [
    "我们所看到的大语言模型，当调用它实现问答的时候，实际上是无状态的，模型本身不会记得你之前问的问题以及回答的内容。\n",
    "\n",
    "但是，我们也有变通的方式，就是将历史的聊天内容，以上下文的方式，和问题一起发送给模型来生成答案，模型自然就知道了之前的聊天内容。为了实现这样的多轮对话，最简单的方式就是我们自己将历史聊天内容进行拼接即可。但是，LangChain 以及帮我们实现好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ed9d3-cd5e-4bc4-a042-bba54726ac30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install langchain==0.0.270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8af703ab-237a-4da4-bc45-eb94b4b87bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.270\n"
     ]
    }
   ],
   "source": [
    "from langchain import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d215561-e344-4c4d-80c5-8ec07b6d141c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt-chatglm2-g4dn\n",
      "mt-cpmbee-g4dn\n",
      "mt-chatglm2-6b-fastllm-fp16-g4dn\n",
      "mt-cn-alpaca2-7b-g5\n",
      "mt-baichuan-g5\n",
      "mt-chatglm2-6b-ft-g4dn\n",
      "mt-sd-2-djl-inf2\n"
     ]
    }
   ],
   "source": [
    "# 查看现有的部署在sagemaker上的endpoints\n",
    "endpoints = !aws sagemaker list-endpoints\n",
    "endpoints = json.loads(\"\".join(endpoints))\n",
    "for ep in endpoints['Endpoints']:\n",
    "    print(ep['EndpointName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bca562-f429-4143-80b6-efc2fdccf30d",
   "metadata": {},
   "source": [
    "首先我们使用 LangChain 框架，生成一个 *SagemakerEndpoint* 类型的 model 对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173092bc-a1fc-422c-b459-cf8c06b11119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prompt_generator import generate_prompt as gen_prompt\n",
    "import prompt_generator as pg\n",
    "import importlib\n",
    "\n",
    "importlib.reload(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1809909-382a-46b0-8fd6-ca380c08cf36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "import json\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input = {\"inputs\": prompt, \"parameters\": {\"temperature\": 0.01}}\n",
    "        logging.info(\"prompt: %s\", prompt)\n",
    "        input_str = json.dumps(input)\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        logger.info(\"response_json: %s\", response_json)\n",
    "        # return response_json[0][\"generated_text\"] # for THI inferencer\n",
    "        return response_json[\"outputs\"]\n",
    "\n",
    "content_handler = ContentHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab4fa824-f06f-40c7-a50c-81c53c94e3ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_endpoint_name = \"mt-chatglm2-g4dn\"\n",
    "\n",
    "chatglm_model = SagemakerEndpoint(\n",
    "    endpoint_name=sagemaker_endpoint_name, \n",
    "    region_name=\"us-east-1\", \n",
    "    content_handler=content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1f535-80f5-403c-aedc-7ebdf8f0f9de",
   "metadata": {},
   "source": [
    "在 LangChain 中，帮我们实现了各种 Memory 对象，用于对聊天历史记录进行管理。然后，在创建 Chain 的时候，只要传递这个 memory 对象，我们的问答机器人就具备了记忆能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac930d72-f385-4eeb-a682-3f45275680a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'prompt_generator' from '/home/ec2-user/SageMaker/LLM_Workshop/prompt_generator.py'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from prompt_generator import generate_prompt as gen_prompt\n",
    "import prompt_generator as pg\n",
    "import importlib\n",
    "\n",
    "importlib.reload(pg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59c2e45f-9f22-4204-b541-f1933e5c0c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain import LLMChain\n",
    "\n",
    "template = \"\"\"You are a chatbot having a conversation with a human.\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "conversation_memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=3)\n",
    "conversation_chain = LLMChain(\n",
    "    llm=chatglm_model,\n",
    "    memory=conversation_memory,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dae4190b-4503-4fe9-b86d-181da3654b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 开始前清除memory\n",
    "conversation_memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "21d44581-1334-4ab8-9219-20f695c3f23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_str = conversation_memory.load_memory_variables({})['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "351401b1-22e2-42a0-999d-f70f202ba5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Human: 你会做数学题吗？',\n",
       " 'AI: 是的，我可以做数学题。请问您有什么数学问题需要帮助吗？',\n",
       " 'Human: 3+4+5等于多少',\n",
       " 'AI: 3+4+5=12',\n",
       " 'Human: 再加5呢？',\n",
       " 'AI: 再加5等于17。']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_str.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c5c55fb4-898f-434a-b061-d033d8690562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '你会做数学题吗？',\n",
       " 'chat_history': '',\n",
       " 'text': '是的，我可以做数学题。请问您有什么数学问题需要帮助吗？'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"你会做数学题吗？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3935a40-1098-4beb-8f32-f972ac0aa7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '3+4+5等于多少',\n",
       " 'chat_history': 'Human: 你会做数学题吗？\\nAI: 是的，我可以做数学题。请问您有什么数学问题需要帮助吗？',\n",
       " 'text': '3+4+5=12'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"3+4+5等于多少\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "477468fc-cc70-42f7-800f-32108341bf7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '再加5呢？',\n",
       " 'chat_history': 'Human: 你会做数学题吗？\\nAI: 是的，我可以做数学题。请问您有什么数学问题需要帮助吗？\\nHuman: 3+4+5等于多少\\nAI: 3+4+5=12',\n",
       " 'text': '再加5等于17。'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"再加5呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f71b7660-30d3-4be8-a79f-797e73e8773f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '再乘以2呢？',\n",
       " 'chat_history': 'Human: 你会做数学题吗？\\nAI: 是的，我可以做数学题。请问您有什么数学问题需要帮助吗？\\nHuman: 3+4+5等于多少\\nAI: 3+4+5=12\\nHuman: 再加5呢？\\nAI: 再加5等于17。',\n",
       " 'text': '再乘以2等于34。'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"再乘以2呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd1d2013-64be-4035-b5a3-0b5403827435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '再减2呢',\n",
       " 'chat_history': 'Human: 3+4+5等于多少\\nAI: 3+4+5=12\\nHuman: 再加5呢？\\nAI: 再加5等于17。\\nHuman: 再乘以2呢？\\nAI: 再乘以2等于34。',\n",
       " 'text': '再减2等于32。'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"再减2呢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedaf1b2-5f56-4fda-bf08-1820f44810dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "761f5395-bfbe-4b3c-9a83-c9c653c61927",
   "metadata": {},
   "source": [
    "#### 测试简单的聊天场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73f3933c-0e79-4674-b303-bff551bd2aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 开始前清除memory\n",
    "conversation_memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beed5640-5e3d-487a-99bf-dacd60f5035c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '我明天去跟暗恋很久的女神吃饭，我应该穿什么衣服？',\n",
       " 'chat_history': '',\n",
       " 'text': '穿什么衣服当然要根据场合和餐厅的要求来选择。一般来说,餐厅会要求比较正式的服装,比如穿西装或礼服。如果餐厅没有特别的要求,你可以选择穿一些比较舒适的衣服,比如牛仔裤或休闲裙。不过,考虑到你是去跟暗恋很久的女神吃饭,最好还是选一些比较正式的衣服,这样会显得更加尊重和恰当。'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"我明天去跟暗恋很久的女神吃饭，我应该穿什么衣服？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc1cf540-b3fd-48a9-a3d6-0fb12fad056f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '可是我没有这样的衣服，有必要买吗？',\n",
       " 'chat_history': 'Human: 我明天去跟暗恋很久的女神吃饭，我应该穿什么衣服？\\nAI: 穿什么衣服当然要根据场合和餐厅的要求来选择。一般来说,餐厅会要求比较正式的服装,比如穿西装或礼服。如果餐厅没有特别的要求,你可以选择穿一些比较舒适的衣服,比如牛仔裤或休闲裙。不过,考虑到你是去跟暗恋很久的女神吃饭,最好还是选一些比较正式的衣服,这样会显得更加尊重和恰当。',\n",
       " 'text': '这取决于场合和重要性。如果这个餐厅非常正式,或者你是去参加一个重要的活动或会议,那么穿正装是必要的。否则,穿着舒适和得体也是可以的。如果你真的没有合适的衣服,也不必非得买一件新的。你可以考虑租一套礼服或者借一件合适的衣服。不过,最重要的是在吃饭时保持整洁和得体,不要穿太暴露或太随意。'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"可是我没有这样的衣服，有必要买吗？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68dfd0-a3fb-48b3-8757-dbb2539c0f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f93096d8-36b0-4527-ba81-dee47a036530",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '那头发呢？',\n",
       " 'chat_history': 'Human: 我明天去跟暗恋很久的女神吃饭，我应该穿什么衣服？\\nAI: 穿什么衣服当然要根据场合和餐厅的要求来选择。一般来说,餐厅会要求比较正式的服装,比如穿西装或礼服。如果餐厅没有特别的要求,你可以选择穿一些比较舒适的衣服,比如牛仔裤或休闲裙。不过,考虑到你是去跟暗恋很久的女神吃饭,最好还是选一些比较正式的衣服,这样会显得更加尊重和恰当。\\nHuman: 可是我没有这样的衣服，有必要买吗？\\nAI: 这取决于场合和重要性。如果这个餐厅非常正式,或者你是去参加一个重要的活动或会议,那么穿正装是必要的。否则,穿着舒适和得体也是可以的。如果你真的没有合适的衣服,也不必非得买一件新的。你可以考虑租一套礼服或者借一件合适的衣服。不过,最重要的是在吃饭时保持整洁和得体,不要穿太暴露或太随意。',\n",
       " 'text': '头发的穿着也很重要,尤其是在正式场合。如果你打算穿正装,建议选择一些简单大方的发型,比如经典的马尾或盘发。如果你选择穿休闲装,可以选择一些比较随意的发型,比如束发或披散。不过,无论你选择什么样的发型,都要确保它们干净整洁,不要油腻或混乱。'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"那头发呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c67df-4e11-4ba6-96cd-0004761d2783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a6481fe-3dc6-4bbc-a5d8-f3b0d857ead6",
   "metadata": {},
   "source": [
    "#### 不同的memory类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abc62d-93ae-462a-8573-4d9c8a7e040f",
   "metadata": {},
   "source": [
    "刚才使用的 Memory 类型是 ConversationBufferWindowMemory，它是基于内存的、有固定窗口大小的对象。我们创建的窗口大小为3，如果对话轮数超过3轮，就会将最老的一个对话记录清除。可以从参数的 “chat_history” 看到历史记录。\n",
    "\n",
    "很显然，这种简单粗暴的方式有时候不适用。还好 LangChain 给我们提供了多种类型的 Memory。下面来看看几种常用的 Memory：\n",
    " * ConversationBufferMemory: 将历史记录保存在Buffer中，如果对话多轮，则有可能会超出buffer大小。\n",
    " * ConversationEntityMemory: 将对话记录中的entity实例提取出来保存起来，在后续的对话中，会根据实体以及它们之间的关系作为上下文，回答用户的问题。\n",
    " * Conversation Knowledge Graph Memory: 使用基于内存的知识库的形式，从用户输入中提取三元组，并保存，用于后续的问答。\n",
    " * ConversationSummaryMemory: 如果不指定对话轮数，而一味的将对话内容保存在memory中的话，很快就会因为超出token限制而出错。如果使用了window memory，则会丢弃老的对话记录。而使用这个ConversationSummaryMemory，他就会根据聊天历史生成summery，再将这个summery信息放到对话上下文中，用于后续对话。这样即使是很多轮对话，也不会超出token显示或丢失重要信息。\n",
    " * VectorStoreRetrieverMemory: 使用这个memory，他会将聊天历史保存在向量数据库中，然后每次对话的时候，根据用户输入查询最相近的几条记录，并作为上下文，回答用户问题。跟这个类似，也有很多将记录保存到各种数据库的memory。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3964a4b-df18-4ede-90d6-6c79db0a3462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom (mt_python3)",
   "language": "python",
   "name": "mt_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
