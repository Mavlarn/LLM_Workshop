{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1409b5-035c-4e66-8ed1-7e06865ad52f",
   "metadata": {},
   "source": [
    "# 部署和使用 Chinese-LLaMA-Alpaca 进行中文问答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36da04a2-c943-4680-864c-678546f920c7",
   "metadata": {},
   "source": [
    "### SageMaker  Endpoint 部署模型\n",
    "  \n",
    "[Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca): Chinese-LLaMA-Alpaca 基于 META AI 的 LLaMA 模型训练的支持中文的大语言模型。\n",
    "\n",
    "首先，我们使用Sagemaker部署ChatGLM模型。\n",
    "#### 准备\n",
    "1. 升级boto3, sagemaker python sdk  \n",
    "2. 准备inference.py, requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb1530-76ea-4bc1-b5e3-7219de5f8ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade boto3\n",
    "# !pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49d80dad-12b2-4228-97db-69a89fcf951a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7e43b-5e84-4a4a-85e6-599e9e47c5a9",
   "metadata": {},
   "source": [
    "接下来，我们使用Sagemaker进行模型部署。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcfce0f1-1d80-4785-9c16-d384c037c507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "model_name = None\n",
    "entry_point = 'inference_alpaca_7b.py'\n",
    "framework_version = '1.13.1'\n",
    "py_version = 'py39'\n",
    "model_environment = {\n",
    "    'SAGEMAKER_MODEL_SERVER_TIMEOUT':'600', \n",
    "    'SAGEMAKER_MODEL_SERVER_WORKERS': '1', \n",
    "}\n",
    "\n",
    "!touch dummy\n",
    "!tar czvf model.tar.gz dummy\n",
    "!rm -f dummy\n",
    "\n",
    "model = PyTorchModel(\n",
    "    name = model_name,\n",
    "    model_data = \"./model.tar.gz\",\n",
    "    entry_point = entry_point,\n",
    "    source_dir = './code_cn_alpaca',\n",
    "    role = role,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    "    env = model_environment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cfe5154-a236-464e-abb4-2235b7e781fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "endpoint_name = \"chinese-alpaca-plus-7b\"\n",
    "instance_type = 'ml.g4dn.xlarge'\n",
    "instance_count = 1\n",
    "\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "predictor = model.deploy(\n",
    "    endpoint_name = endpoint_name,\n",
    "    instance_type = instance_type,\n",
    "    initial_instance_count = instance_count,\n",
    "    serializer = JSONSerializer(),\n",
    "    deserializer = JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a0ab3c7-e5ed-492e-a615-9310ba0069e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt(text):\n",
    "    return {\"ask\": f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9ef84a5-8268-4b0e-87dc-85d974d12873",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.71 ms, sys: 0 ns, total: 4.71 ms\n",
      "Wall time: 1.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': '这是因为大气中的气体分子会散射太阳光，其中蓝色波长的光线更容易被散射。'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predictor.predict(generate_prompt(\"天空为什么是蓝色的\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "759a0e0b-6a25-4e02-844f-928dbbf8f871",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "问题:  写一首关于交通信号灯的诗 \n",
      "回答:\n",
      " 红绿相间，行人匆匆过；\n",
      "绿灯亮起时，车流如梭飞。\n",
      "黄灯鸣响处，车辆停下歇息；\n",
      "红灯闪烁时，人们等待通行。\n",
      "\n",
      "\n",
      "问题:  陨石为什么总能落在陨石坑里? \n",
      "回答:\n",
      " 陨石之所以能够落入陨石坑，是因为它们受到重力的影响。当一颗小行星撞击地球时，它会释放出大量的能量和物质，其中一部分被吸收了，另一部分则形成了陨石坑。由于陨石的密度比周围的岩石要大得多，所以它们更容易被引力吸引到陨石坑中。\n",
      "\n",
      "\n",
      "问题:  为什么爸妈结婚没叫我参加婚礼? \n",
      "回答:\n",
      " 很抱歉，我无法回答你的问题。请理解我的能力和范围。\n"
     ]
    }
   ],
   "source": [
    "inputs= [\n",
    "    {\"ask\": \"写一首关于交通信号灯的诗\"},\n",
    "    {\"ask\": \"陨石为什么总能落在陨石坑里?\" },\n",
    "    {\"ask\": \"为什么爸妈结婚没叫我参加婚礼?\"}\n",
    "]\n",
    "response = predictor.predict(generate_prompt(inputs[0]))\n",
    "print(\"\\n\\n问题: \", inputs[0][\"ask\"], \"\\n回答:\\n\", response[\"answer\"])\n",
    "response = predictor.predict(generate_prompt(inputs[1]))\n",
    "print(\"\\n\\n问题: \", inputs[1][\"ask\"], \"\\n回答:\\n\", response[\"answer\"])\n",
    "response = predictor.predict(generate_prompt(inputs[2]))\n",
    "print(\"\\n\\n问题: \", inputs[2][\"ask\"], \"\\n回答:\\n\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ccebb-73aa-4cca-af80-09e9b6df6bde",
   "metadata": {
    "tags": []
   },
   "source": [
    "也可以通过Endpoint Name进行调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1224ec8-4378-4f13-8546-f4d51ec3cfa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "sagemaker_endpoint_name = endpoint_name\n",
    "\n",
    "client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "def query_endpoint(query):\n",
    "    encoded_json = json.dumps({\"ask\": query}).encode('utf-8')\n",
    "    response = client.invoke_endpoint(EndpointName=sagemaker_endpoint_name, ContentType='application/json', Body=encoded_json)\n",
    "    model_predictions = json.loads(response['Body'].read())\n",
    "    generated_text = model_predictions[\"answer\"]\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89e57d6c-73d6-4cb7-94d2-15e76cbbf3d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'给定一个文字输入，将其中的所有数字加1。\\n“明天的会议在9点开始，记得准时到达。”\\n转换为数字后：“明天的会议在10点开始，记得准时到达。”'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_endpoint(\"给定一个文字输入，将其中的所有数字加1。\\n“明天的会议在9点开始，记得准时到达。”\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20109431-9291-4d7e-aad0-f6b595507e7e",
   "metadata": {},
   "source": [
    "### 删除Endpoint\n",
    "如果部署的模型已经不使用，可以删除 Endpoint，避免不必要的开支。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e8fc003-948f-43aa-af00-ddf25902852c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b734b83-06e3-49b6-b16d-f830c0d9eb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6c13275-5cde-4dba-ac47-3893a90cdfe0",
   "metadata": {},
   "source": [
    "### 13B 模型\n",
    "13B模型大小大概是23G，所以使用g5系列的实例，它的GPU是A10系列，现存是24GB。而且，我们需要用8-bit量化的方式部署，否则24GB的现存，也只是够部署的，但是在推理的时候，会出现OutOfMemory的错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f177b908-60c1-4f3f-af1d-e6369d2ec9f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "model_name = None\n",
    "entry_point = 'inference_alpaca.py'\n",
    "framework_version = '1.13.1'\n",
    "py_version = 'py39'\n",
    "model_environment = {\n",
    "    'SAGEMAKER_MODEL_SERVER_TIMEOUT':'600', \n",
    "    'SAGEMAKER_MODEL_SERVER_WORKERS': '1', \n",
    "}\n",
    "\n",
    "!touch dummy\n",
    "!tar czvf model.tar.gz dummy\n",
    "!rm -f dummy\n",
    "\n",
    "model_13 = PyTorchModel(\n",
    "    name = model_name,\n",
    "    model_data = \"./model.tar.gz\",\n",
    "    entry_point = entry_point,\n",
    "    source_dir = './code_cn_alpaca',\n",
    "    role = role,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    "    env = model_environment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de59bb3d-842d-4b8f-bce7-d778ad38f67a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "endpoint_name = \"chinese-alpaca-plus-13b\"\n",
    "instance_type = 'ml.g5.2xlarge'\n",
    "instance_count = 1\n",
    "\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "predictor_13 = model_13.deploy(\n",
    "    endpoint_name = endpoint_name,\n",
    "    instance_type = instance_type,\n",
    "    initial_instance_count = instance_count,\n",
    "    serializer = JSONSerializer(),\n",
    "    deserializer = JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfdf5f4-c214-4340-bf0f-38ac97fec909",
   "metadata": {
    "tags": []
   },
   "source": [
    "由于13B的模型较大，使用具有24G显存的g5的机型进行部署，如果不进行量化，也无法部署成功，所以使用8bit方式量化部署，才能部署成功，但是推理的时间很长。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bbbcfb-32ae-43e6-874a-13deb5717915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt(text):\n",
    "    return {\"ask\": f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{text}\n",
    "\n",
    "### Response:\"\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd201719-862b-4d48-bad9-b995ad2d153b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.5 ms, sys: 0 ns, total: 48.5 ms\n",
      "Wall time: 23.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': '海水看起来是蓝色的是因为太阳光在穿过大气层时，会发生散射现象。当光线遇到水滴或气体分子时，一部分会被反射回来，而另一部分则被折射到不同的方向上。在这个过程中，短波长的蓝光更容易被分散和反射，因此我们看到的海水通常呈现出蓝色的颜色。 此外，海水中的微粒（如浮游生物、盐分等）也会对颜色产生影响，它们会使海水呈现绿色、棕色甚至红色等不同色调。 因此，海水的颜色并不是单一的原因所决定的，而是由多种因素共同作用的结果。'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predictor_13.predict(generate_prompt(\"海为什么是蓝色的\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be322c-999f-4d44-b5b7-20fb9889f7df",
   "metadata": {},
   "source": [
    "简单的推理，使用了近25秒。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf8ae61e-f82d-4a2b-9420-05c48844f72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('runtime.sagemaker')\n",
    "\n",
    "def query_endpoint(encoded_json):\n",
    "    response = client.invoke_endpoint(EndpointName=\"chinese-alpaca-plus-13b\", ContentType='application/json', Body=encoded_json)\n",
    "    model_predictions = json.loads(response['Body'].read())\n",
    "    generated_text = model_predictions[\"answer\"]\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1124a196-871d-4474-9fba-b052cba191ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国家名：阿根廷；人名：梅西。\n",
      "CPU times: user 5.57 ms, sys: 0 ns, total: 5.57 ms\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = generate_prompt(\"信息抽取：\\n2022年世界杯的冠军是阿根廷队伍，梅西是MVP\\n问题：国家名，人名\\n\")\n",
    "resp_test = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(resp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25eb60c7-0643-4e2f-96df-c0061bc27b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿根廷，梅西\n"
     ]
    }
   ],
   "source": [
    "payload = generate_prompt(\"信息抽取：\\n2022年世界杯的冠军是阿根廷队伍，梅西是MVP\\n问题：国家名，人名\\n答案：\")\n",
    "resp_test = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(resp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "185f89ce-aff2-4c4c-bd9b-57802fac2aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "信息抽取：\n",
      "2022年世界杯的冠军是阿根廷队伍，梅西是MVP\n",
      "问题：国家名，人名\n",
      "答案：阿根廷，梅西 ->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "payload = {\"ask\": \"信息抽取：\\n2022年世界杯的冠军是阿根廷队伍，梅西是MVP\\n问题：国家名，人名\\n答案：\"}\n",
    "resp_test = query_endpoint(json.dumps(payload).encode('utf-8'))\n",
    "print(resp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba406951-1898-4543-b374-5ed05f626692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor_13.delete_model()\n",
    "predictor_13.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f07a8e-8f29-4231-9af2-d2e2f9a50825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
