{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77ac247-aa6f-4802-95c2-66ee886800d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.30.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import __version__\n",
    "__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e84697-7e4a-47a6-8917-0d1a355d41c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install \"datasets[s3]==2.13.0\" sagemaker --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b4fff-ebd8-404d-9ab2-12d2431ecb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c46a33-93de-4601-9329-ced7856748df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ec2-user/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36ee95-e882-4af1-bbb5-612fe4582d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec79b66-3bed-4230-a316-2721c38182d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::568765279027:role/service-role/AmazonSageMaker-ExecutionRole-20220224T172259\n",
      "sagemaker bucket: sagemaker-us-east-1-568765279027\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c9beec3-7d8e-4c49-a65b-fa3c5ac74176",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/ec2-user/.cache/huggingface/datasets/databricks___json/databricks--databricks-dolly-15k-7427aa6e57c34282/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 15011\n",
      "{'instruction': 'What is Cricket in sports?', 'context': 'Cricket is a bat-and-ball game played between two teams of eleven players on a field at the centre of which is a 22-yard (20-metre) pitch with a wicket at each end, each comprising two bails balanced on three stumps. The batting side scores runs by striking the ball bowled at one of the wickets with the bat and then running between the wickets, while the bowling and fielding side tries to prevent this (by preventing the ball from leaving the field, and getting the ball to either wicket) and dismiss each batter (so they are \"out\"). Means of dismissal include being bowled, when the ball hits the stumps and dislodges the bails, and by the fielding side either catching the ball after it is hit by the bat, but before it hits the ground, or hitting a wicket with the ball before a batter can cross the crease in front of the wicket. When ten batters have been dismissed, the innings ends and the teams swap roles. The game is adjudicated by two umpires, aided by a third umpire and match referee in international matches. They communicate with two off-field scorers who record the match\\'s statistical information.\\n\\nForms of cricket range from Twenty20, with each team batting for a single innings of 20 overs (each \"over\" being a set of 6 fair opportunities for the batting team to score) and the game generally lasting three hours, to Test matches played over five days. Traditionally cricketers play in all-white kit, but in limited overs cricket they wear club or team colours. In addition to the basic kit, some players wear protective gear to prevent injury caused by the ball, which is a hard, solid spheroid made of compressed leather with a slightly raised sewn seam enclosing a cork core layered with tightly wound string.', 'response': \"Cricket is highly popular game that's originated in south-eastern counties of England and now prominent sport in a number of countries in particular south asian countries like India, Pakistan, Sri Lanka and Bangladesh.\\nIt is in essence a bat-and-ball game played between two teams of eleven players on a field. The batting side scores runs by striking the ball with the bat and then running between the wickets, while the bowling and fielding side tries to prevent this and dismiss each batter.\\nForms of cricket range from Twenty20, one day to Test match lasting up to 5 days. The game originated as children's game is now a highly competitive professional sport followed by billions of people and in last decade commercialised at club level with the introduction of Indian Premier League (IPL).\", 'category': 'closed_qa'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "# from pathlib import Path\n",
    "\n",
    "# local_cache_path = Path(\"data/databricks/databricks-dolly-15k\")\n",
    "# local_cache_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
    "\n",
    "print(f\"dataset size: {len(dataset)}\")\n",
    "print(dataset[randrange(len(dataset))])\n",
    "# dataset size: 15011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdad9772-c88d-47bf-9d0f-10400a91c1f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_dolly(sample):\n",
    "    instruction = f\"### Instruction\\n{sample['instruction']}\"\n",
    "    context = f\"### Context\\n{sample['context']}\" if len(sample[\"context\"]) > 0 else None\n",
    "    response = f\"### Answer\\n{sample['response']}\"\n",
    "    # join all the parts together\n",
    "    prompt = \"\\n\\n\".join([i for i in [instruction, context, response] if i is not None])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa749250-b664-42f1-95f8-c5ab7f0ced9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction\n",
      "Which of these movies were nominated for Best Picture?  \"All Quiet on the Western Front\", \"Everything Everywhere All at Once\", \"Avatar:  The Way of Water\", \"Glass Onion\", \"Pinocchio\", \"Navalny\", \"The Whale\".\n",
      "\n",
      "### Answer\n",
      "The following films were nominated for Best Picture in the 2023 Academy Awards:  \"All Quiet on the Western Front\", \"Everything Everywhere All at Once\", and \"Avatar:  The Way of Water\".  \"Everything Everywhere All at Once\" won Best Picture.\n",
      "\n",
      "While the other films weren't nominated for Best Picture, they were nominated for the following Academy Awards.  \"Glass Onion:  A Knives Out Mystery\" was nominated for Best Adapted Screenplay.  \"Guillermo Del Toro's Pinocchio\" won Best Animated Feature Film.  \"Navalny\" won Best Documentary Feature Film.  And \"The Whale\" won twice:  Brendan Fraser for Best Actor in a Leading Role; Adrien Morot, Judy Chin and Annemarie Bradley for Best Makeup and Hairstyling.\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "print(format_dolly(dataset[randrange(len(dataset))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f382e7a-fbf2-4d7b-b706-2beb211eb30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a02a966-83cb-4e32-a17c-c044c47103cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-2-13b-hf\" # sharded weights\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,use_auth_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5763c89a-d7be-44d9-a44d-9c8fac294ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "# ori_dataset = dataset\n",
    "dataset = Dataset.from_dict(ori_dataset[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba46c70b-b515-434e-b2e7-2fdf61623685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = ori_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c784aed8-cecc-4f01-8603-ae592ba263cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15011"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(dataset[1])\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6569d258-a4f2-439a-851d-243088476a18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Which is a species of fish? Tope or Rope',\n",
       " 'context': '',\n",
       " 'response': 'Tope',\n",
       " 'category': 'classification'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39872d09-1231-41db-affd-a866a58f7a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lll = dataset.map(lambda x: x).map(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c95e665-1ff3-42d7-961b-5b94cebbfac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/databricks___json/databricks--databricks-dolly-15k-7427aa6e57c34282/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-da78202413268ee7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction\n",
      "Where should I go this summer?\n",
      "\n",
      "### Answer\n",
      "It depends, for many people, a summer destination is all about going to a nice beach, enjoying the sunshine and relaxing. For others summer vacation is about going on a new adventure to explore a nice country, city or a cool nearby village. \n",
      "Here are some ideas for a summer vacation if you are interested in traveling to Europe\n",
      "Road trip across the Amalfi coast for one week. \n",
      "Cruising around the Croatian islands. \n",
      "Ancient history tour in Rome, Vatican City & Athens.\n",
      "Enjoy the beautiful beaches in Southern France. \n",
      "There are many other beautiful places to visit but this will depend on your budget, duration and your interests.</s>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_dolly(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "\n",
    "# apply prompt template per sample\n",
    "dataset = dataset.map(template_dataset, remove_columns=list(dataset.features))\n",
    "# print random sample\n",
    "print(dataset[randint(0, len(dataset))][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3eddaffb-e859-435b-b7d7-d6732c21578d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15011"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1740d221-3b18-472a-bc84-94f6c87c88de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### Instruction\\nWhich is a species of fish? Tope or Rope\\n\\n### Answer\\nTope</s>'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6c667f0-f812-422f-b711-06a7376cdea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3060e65e-c3f3-4777-b088-86cedb37ce30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/15011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n",
      "training dataset to: s3://sagemaker-us-east-1-568765279027/llm/datasets/dolly/train\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "#放在同一的路径下：\n",
    "# 'med_qa': f\"s3://{sagemaker_default_bucket}/llm/datasets/chatglm2/med_qa/\"\n",
    "\n",
    "training_input_path = f's3://{sess.default_bucket()}/llm/datasets/dolly/train'\n",
    "dataset.save_to_disk(training_input_path)\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "print(f\"training dataset to: {training_input_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d82232-5fc1-4c53-a527-4c43987363aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "169a19a5-48ba-48ae-9e36-034eccd65ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# model_id = \"meta-llama/Llama-2-13b-hf\"\n",
    "\n",
    "# define Training Job Name \n",
    "job_name = f'llama2-qlora-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'epochs': 3,                                      # number of training epochs\n",
    "  'per_device_train_batch_size': 2,                 # batch size for training\n",
    "  'lr': 2e-4,                                       # learning rate used during training\n",
    "  'hf_token': HfFolder.get_token(),                 # huggingface token to access llama 2\n",
    "  'merge_weights': False,                            # wether to merge LoRA into the model (needs more memory)\n",
    "}\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_clm.py',      # train script\n",
    "    source_dir           = 'llama2-finetune-qlora',         # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.4xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = {\n",
    "        \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\",\n",
    "    \n",
    "    }, # set env variable to cache models in /tmp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52337175-91d4-46d9-b624-45bb8911d984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: llama2-qlora-2023-07-29-16-14-40-2023-07-29-16-14-46-387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-07-29 16:14:46 Starting - Starting the training job...\n",
      "2023-07-29 16:15:02 Starting - Preparing the instances for training......\n",
      "2023-07-29 16:16:10 Downloading - Downloading input data...\n",
      "2023-07-29 16:16:31 Training - Downloading the training image.........."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_input_path}\n",
    "\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ebbf55b-ae09-4b7b-a551-b89ae3f0dcd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m           HuggingFace\n",
       "\u001b[0;31mString form:\u001b[0m    <sagemaker.huggingface.estimator.HuggingFace object at 0x7f0315805240>\n",
       "\u001b[0;31mFile:\u001b[0m           ~/SageMaker/custom-miniconda/miniconda/envs/mt_python3/lib/python3.10/site-packages/sagemaker/huggingface/estimator.py\n",
       "\u001b[0;31mDocstring:\u001b[0m      Handle training of custom HuggingFace code.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "This estimator runs a Hugging Face training script in a SageMaker training environment.\n",
       "\n",
       "The estimator initiates the SageMaker-managed Hugging Face environment\n",
       "by using the pre-built Hugging Face Docker container and runs\n",
       "the Hugging Face training script that user provides through\n",
       "the ``entry_point`` argument.\n",
       "\n",
       "After configuring the estimator class, use the class method\n",
       ":meth:`~sagemaker.amazon.estimator.Framework.fit()` to start a training job.\n",
       "\n",
       "Args:\n",
       "    py_version (str): Python version you want to use for executing your model training\n",
       "        code. Defaults to ``None``. Required unless ``image_uri`` is provided.  If\n",
       "        using PyTorch, the current supported version is ``py36``. If using TensorFlow,\n",
       "        the current supported version is ``py37``.\n",
       "    entry_point (str or PipelineVariable): Path (absolute or relative) to the Python source\n",
       "        file which should be executed as the entry point to training.\n",
       "        If ``source_dir`` is specified, then ``entry_point``\n",
       "        must point to a file located at the root of ``source_dir``.\n",
       "    transformers_version (str): Transformers version you want to use for\n",
       "        executing your model training code. Defaults to ``None``. Required unless\n",
       "        ``image_uri`` is provided. The current supported version is ``4.6.1``.\n",
       "    tensorflow_version (str): TensorFlow version you want to use for\n",
       "        executing your model training code. Defaults to ``None``. Required unless\n",
       "        ``pytorch_version`` is provided. The current supported version is ``2.4.1``.\n",
       "    pytorch_version (str): PyTorch version you want to use for\n",
       "        executing your model training code. Defaults to ``None``. Required unless\n",
       "        ``tensorflow_version`` is provided. The current supported versions are ``1.7.1`` and ``1.6.0``.\n",
       "    source_dir (str or PipelineVariable): Path (absolute, relative or an S3 URI) to a\n",
       "        directory with any other training source code dependencies aside from the entry\n",
       "        point file (default: None). If ``source_dir`` is an S3 URI, it must\n",
       "        point to a tar.gz file. Structure within this directory are preserved\n",
       "        when training on Amazon SageMaker.\n",
       "    hyperparameters (dict[str, str] or dict[str, PipelineVariable]): Hyperparameters\n",
       "        that will be used for training (default: None). The hyperparameters are made\n",
       "        accessible as a dict[str, str] to the training code on\n",
       "        SageMaker. For convenience, this accepts other types for keys\n",
       "        and values, but ``str()`` will be called to convert them before\n",
       "        training.\n",
       "    image_uri (str or PipelineVariable): If specified, the estimator will use this image\n",
       "        for training and hosting, instead of selecting the appropriate\n",
       "        SageMaker official image based on framework_version and\n",
       "        py_version. It can be an ECR url or dockerhub image and tag.\n",
       "        Examples:\n",
       "            * ``123412341234.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0``\n",
       "            * ``custom-image:latest``\n",
       "\n",
       "        If ``framework_version`` or ``py_version`` are ``None``, then\n",
       "        ``image_uri`` is required. If also ``None``, then a ``ValueError``\n",
       "        will be raised.\n",
       "    distribution (dict): A dictionary with information on how to run distributed training\n",
       "        (default: None).  Currently, the following are supported:\n",
       "        distributed training with parameter servers, SageMaker Distributed (SMD) Data\n",
       "        and Model Parallelism, and MPI. SMD Model Parallelism can only be used with MPI.\n",
       "        To enable parameter server use the following setup:\n",
       "\n",
       "        .. code:: python\n",
       "\n",
       "            {\n",
       "                \"parameter_server\": {\n",
       "                    \"enabled\": True\n",
       "                }\n",
       "            }\n",
       "\n",
       "        To enable MPI:\n",
       "\n",
       "        .. code:: python\n",
       "\n",
       "            {\n",
       "                \"mpi\": {\n",
       "                    \"enabled\": True\n",
       "                }\n",
       "            }\n",
       "\n",
       "        To enable SMDistributed Data Parallel or Model Parallel:\n",
       "\n",
       "        .. code:: python\n",
       "\n",
       "            {\n",
       "                \"smdistributed\": {\n",
       "                    \"dataparallel\": {\n",
       "                        \"enabled\": True\n",
       "                    },\n",
       "                    \"modelparallel\": {\n",
       "                        \"enabled\": True,\n",
       "                        \"parameters\": {}\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "\n",
       "        **To enable PyTorch DDP:**\n",
       "\n",
       "            .. code:: python\n",
       "\n",
       "                {\n",
       "                    \"pytorchddp\": {\n",
       "                        \"enabled\": True\n",
       "                    }\n",
       "                }\n",
       "\n",
       "            To learn more, see `Distributed PyTorch Training\n",
       "            <https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#distributed-pytorch-training>`_.\n",
       "\n",
       "        **To enable Torch Distributed:**\n",
       "\n",
       "            This is available for general distributed training on\n",
       "            GPU instances from PyTorch v1.13.1 and later.\n",
       "\n",
       "            .. code:: python\n",
       "\n",
       "                {\n",
       "                    \"torch_distributed\": {\n",
       "                        \"enabled\": True\n",
       "                    }\n",
       "                }\n",
       "\n",
       "            This option also supports distributed training on Trn1.\n",
       "            To learn more, see `Distributed PyTorch Training on Trainium\n",
       "            <https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#distributed-pytorch-training-on-trainium>`_.\n",
       "\n",
       "        To enable distributed training with\n",
       "        `SageMaker Training Compiler <https://docs.aws.amazon.com/sagemaker/latest/dg/training-compiler.html>`_\n",
       "        for Hugging Face Transformers with PyTorch:\n",
       "\n",
       "        .. code:: python\n",
       "\n",
       "            {\n",
       "                \"pytorchxla\": {\n",
       "                    \"enabled\": True\n",
       "                }\n",
       "            }\n",
       "\n",
       "        To learn more, see `SageMaker Training Compiler\n",
       "        <https://docs.aws.amazon.com/sagemaker/latest/dg/training-compiler.html>`_\n",
       "        in the *Amazon SageMaker Developer Guide*.\n",
       "\n",
       "        .. note::\n",
       "\n",
       "            When you use this PyTorch XLA option for distributed training strategy,\n",
       "            you must add the ``compiler_config`` parameter and activate SageMaker\n",
       "            Training Compiler.\n",
       "    compiler_config (:class:`~sagemaker.huggingface.TrainingCompilerConfig`):\n",
       "        Configures SageMaker Training Compiler to accelerate training.\n",
       "\n",
       "    **kwargs: Additional kwargs passed to the :class:`~sagemaker.estimator.Framework`\n",
       "        constructor.\n",
       "\n",
       ".. tip::\n",
       "\n",
       "    You can find additional parameters for initializing this class at\n",
       "    :class:`~sagemaker.estimator.Framework` and\n",
       "    :class:`~sagemaker.estimator.EstimatorBase`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "huggingface_estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084e3cf-7eae-4fe4-b066-ecd40dde35d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c053342-7748-499e-8ffe-c1cbd0346d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c379d29-9b1f-4141-bdf5-0d807aa027ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "774f64a0-e9f4-4d42-9ad1-386a24effca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm_dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e894879-4f33-4d2e-a04c-3d182261ce5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        Dataset\n",
       "\u001b[0;31mString form:\u001b[0m\n",
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1\n",
       "})\n",
       "\u001b[0;31mLength:\u001b[0m      1\n",
       "\u001b[0;31mFile:\u001b[0m        ~/SageMaker/custom-miniconda/miniconda/envs/mt_python3/lib/python3.10/site-packages/datasets/arrow_dataset.py\n",
       "\u001b[0;31mDocstring:\u001b[0m   A Dataset backed by an Arrow table."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?lm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5ec62-a2c9-47ad-94b1-59028f90070a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom (mt_python3)",
   "language": "python",
   "name": "mt_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
