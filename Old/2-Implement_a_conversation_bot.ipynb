{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd60e60-ec2b-47d9-af02-d126c91a0ccb",
   "metadata": {},
   "source": [
    "### 使用ChatGLM实现多轮对话机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e736e0-8577-4334-ad46-a5570e52896a",
   "metadata": {},
   "source": [
    "我们所看到的大语言模型，当调用它实现问答的时候，实际上是无状态的，模型本身不会记得你之前问的问题以及回答的内容。\n",
    "\n",
    "但是，我们也有变通的方式，就是将历史的聊天内容，以上下文的方式，和问题一起发送给模型来生成答案，模型自然就知道了之前的聊天内容。为了实现这样的多轮对话，最简单的方式就是我们自己将历史聊天内容进行拼接即可。但是，LangChain 以及帮我们实现好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ed9d3-cd5e-4bc4-a042-bba54726ac30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af703ab-237a-4da4-bc45-eb94b4b87bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.235\n"
     ]
    }
   ],
   "source": [
    "from langchain import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bca562-f429-4143-80b6-efc2fdccf30d",
   "metadata": {},
   "source": [
    "首先我们使用 LangChain 框架，生成一个 *SagemakerEndpoint* 类型的 model 对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1809909-382a-46b0-8fd6-ca380c08cf36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "import json\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input = {\"ask\": prompt, **model_kwargs}\n",
    "        logger.info(\"prompt: %s\", prompt)\n",
    "        logger.info(\"model_kwargs: %s\", model_kwargs)\n",
    "        input_str = json.dumps(input)\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        logger.info(\"response_json: %s\", response_json)\n",
    "        return response_json[\"answer\"]\n",
    "\n",
    "content_handler = ContentHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4fa824-f06f-40c7-a50c-81c53c94e3ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_endpoint_name = \"mt-chatglm2-6b-g4dn\"\n",
    "\n",
    "chatglm_model = SagemakerEndpoint(\n",
    "    endpoint_name=sagemaker_endpoint_name, \n",
    "    region_name=\"us-east-1\", \n",
    "    model_kwargs={\"temperature\": 0.1},\n",
    "    content_handler=content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1f535-80f5-403c-aedc-7ebdf8f0f9de",
   "metadata": {},
   "source": [
    "在 LangChain 中，帮我们实现了各种 Memory 对象，用于对聊天历史记录进行管理。然后，在创建 Chain 的时候，只要传递这个 memory 对象，我们的问答机器人就具备了记忆能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c2e45f-9f22-4204-b541-f1933e5c0c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain import LLMChain\n",
    "\n",
    "template = \"\"\"You are a chatbot having a conversation with a human.\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "conversation_memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=3)\n",
    "conversation_chain = LLMChain(\n",
    "    llm=chatglm_model,\n",
    "    memory=conversation_memory,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dae4190b-4503-4fe9-b86d-181da3654b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 开始前清除memory\n",
    "conversation_memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c55fb4-898f-434a-b061-d033d8690562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '你会做数学题吗？',\n",
       " 'chat_history': '',\n",
       " 'text': '是的，我可以做数学题。请问您有什么数学问题需要帮助吗？'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"你会做数学题吗？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3935a40-1098-4beb-8f32-f972ac0aa7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '3+4+5等于多少',\n",
       " 'chat_history': 'Human: 你会做数学题吗？\\nAI: 是的，我可以做数学题。请问您有什么数学问题需要帮助吗？',\n",
       " 'text': '3+4+5=12'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"3+4+5等于多少\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "477468fc-cc70-42f7-800f-32108341bf7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '再加5呢？',\n",
       " 'chat_history': 'Human: 你会做数学题吗？\\nAI: 是的，我可以做数学题。请问您有什么数学问题需要帮助吗？\\nHuman: 3+4+5等于多少\\nAI: 3+4+5=12',\n",
       " 'text': '再加5等于17。'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"再加5呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f71b7660-30d3-4be8-a79f-797e73e8773f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '再乘以2呢？',\n",
       " 'chat_history': 'Human: 你会做数学题吗？\\nAI: 是的，我可以做数学题。请问您有什么数学问题需要帮助吗？\\nHuman: 3+4+5等于多少\\nAI: 3+4+5=12\\nHuman: 再加5呢？\\nAI: 再加5等于17。',\n",
       " 'text': '再乘以2等于34。'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"再乘以2呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd1d2013-64be-4035-b5a3-0b5403827435",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '再减2呢',\n",
       " 'chat_history': 'Human: 3+4+5等于多少\\nAI: 3+4+5=12\\nHuman: 再加5呢？\\nAI: 再加5等于17。\\nHuman: 再乘以2呢？\\nAI: 再乘以2等于34。',\n",
       " 'text': '再减2等于32。'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain(\"再减2呢\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f5395-bfbe-4b3c-9a83-c9c653c61927",
   "metadata": {},
   "source": [
    "#### 使用 Chinese LLaMA Alpaca 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26084b18-fe21-401c-be85-72f7633de7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#创建 LangChain SagemakerEndpoint 的模型：\n",
    "alpaca_model = SagemakerEndpoint(\n",
    "    endpoint_name=\"chinese-alpaca-plus-7b\", \n",
    "    region_name=\"us-east-1\", \n",
    "    model_kwargs={\"temperature\": 0.01},\n",
    "    content_handler=content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1502569b-8985-4d7d-98cc-2943029a2b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain import LLMChain\n",
    "\n",
    "template2 = \"\"\"You are a chatbot having a conversation with a human. Try to answer the question in Chinese.\n",
    "{chat_history}\n",
    "\n",
    "{human_input}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template2\n",
    ")\n",
    "conversation_memory2 = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=3)\n",
    "conversation_chain2 = LLMChain(\n",
    "    llm=alpaca_model,\n",
    "    memory=conversation_memory2,\n",
    "    prompt=prompt2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b21923ee-c8a3-4bbb-a37e-e2bcb143f21e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation_memory2.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d07ac0de-9c0f-4762-803f-cd999c3cb36b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '你会做数学题吗？', 'chat_history': '', 'text': '是的，我会做数学题。'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain2(\"你会做数学题吗？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5702aab4-7a27-4621-b9fb-191ab981fb29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '3+4+5等于多少',\n",
       " 'chat_history': 'Human: 你会做数学题吗？\\nAI: 是的，我会做数学题。',\n",
       " 'text': '3加4加5等于12'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain2(\"3+4+5等于多少\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "756e6e28-14e0-4ce4-9518-b48e8ae38d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '再加5呢？',\n",
       " 'chat_history': 'Human: 你会做数学题吗？\\nAI: 是的，我会做数学题。\\nHuman: 3+4+5等于多少\\nAI: 3加4加5等于12',\n",
       " 'text': '12 + 5 = 17'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain2(\"再加5呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55250b6d-5262-4d5e-bb29-6dfff941028b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '再乘以2呢？',\n",
       " 'chat_history': 'Human: 你会做数学题吗？\\nAI: 是的，我会做数学题。\\nHuman: 3+4+5等于多少\\nAI: 3加4加5等于12\\nHuman: 再加5呢？\\nAI: 12 + 5 = 17',\n",
       " 'text': '2 x 17 = 34'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain2(\"再乘以2呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c8429da-0b6d-4997-ad3b-972bfebe700c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human_input': '再减2呢?',\n",
       " 'chat_history': 'Human: 3+4+5等于多少\\nAI: 3加4加5等于12\\nHuman: 再加5呢？\\nAI: 12 + 5 = 17\\nHuman: 再乘以2呢？\\nAI: 2 x 17 = 34',\n",
       " 'text': '-34-2=-36'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain2(\"再减2呢?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c670a-b9bc-4419-8c58-4a2cb49bf1f9",
   "metadata": {},
   "source": [
    "### 测试结果\n",
    "根据测试，Chinese LLaMA Alpaca 模型和 ChatGLM 模型都能得到比较好的效果，但是有时候会出现“计算出错”。对于这种计算问题，更好的方式是使用大语言模型生成代码，然后再通过Evaluate执行代码，返回计算的结果。但是这里只是测试多轮对话的能力和实现方式。\n",
    "\n",
    "但是13B的模型，不知道是调优的时候使用的数据的问题，还是提示词的问题，在结果中会出现很多<p>这样的字符，而使用 Chinese LLaMA Alpaca 7B的模型，效果会比较好。但是连续多轮计算之后，总是容易出现错误。如果在提示词里，针对数学计算提供专门的提示可能会好一些。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6481fe-3dc6-4bbc-a5d8-f3b0d857ead6",
   "metadata": {},
   "source": [
    "#### 不同的memory类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abc62d-93ae-462a-8573-4d9c8a7e040f",
   "metadata": {},
   "source": [
    "刚才使用的 Memory 类型是 ConversationBufferWindowMemory，它是基于内存的、有固定窗口大小的对象。我们创建的窗口大小为3，如果对话轮数超过3轮，就会将最老的一个对话记录清除。可以从参数的 “chat_history” 看到历史记录。\n",
    "\n",
    "很显然，这种简单粗暴的方式有时候不适用。还好 LangChain 给我们提供了多种类型的 Memory。下面来看看几种常用的 Memory：\n",
    " * ConversationBufferMemory: 将历史记录保存在Buffer中，如果对话多轮，则有可能会超出buffer大小。\n",
    " * ConversationEntityMemory: 将对话记录中的entity实例提取出来保存起来，在后续的对话中，会根据实体以及它们之间的关系作为上下文，回答用户的问题。\n",
    " * Conversation Knowledge Graph Memory: 使用基于内存的知识库的形式，从用户输入中提取三元组，并保存，用于后续的问答。\n",
    " * ConversationSummaryMemory: 如果不指定对话轮数，而一味的将对话内容保存在memory中的话，很快就会因为超出token限制而出错。如果使用了window memory，则会丢弃老的对话记录。而使用这个ConversationSummaryMemory，他就会根据聊天历史生成summery，再将这个summery信息放到对话上下文中，用于后续对话。这样即使是很多轮对话，也不会超出token显示或丢失重要信息。\n",
    " * VectorStoreRetrieverMemory: 使用这个memory，他会将聊天历史保存在向量数据库中，然后每次对话的时候，根据用户输入查询最相近的几条记录，并作为上下文，回答用户问题。跟这个类似，也有很多将记录保存到各种数据库的memory。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3964a4b-df18-4ede-90d6-6c79db0a3462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
